{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural network: Example and exercise with Keras\n",
    "\n",
    "- An example of classification into 10 classes of MNIST data is provided for you\n",
    "- You are then given an another set of data (malaria parasite vs non-affected ones): your tasks are described after this exercise\n",
    "- Please pay attention and look into how Keras is working and try to change or build your own network and observe its effect on your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "data = np.load('datasets/MNIST_data/mnist.npz')\n",
    "x_train= data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),input_shape=input_shape))\n",
    "model.add(BatchNormalization(momentum=0.95))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization(momentum=0.95))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3)))   \n",
    "model.add(BatchNormalization(momentum=0.95))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(BatchNormalization(momentum=0.95))\n",
    "model.add(Activation('relu'))\n",
    "          \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Flatten()) # we can flatten or use a global pooling scheme.\n",
    "model.add(GlobalAveragePooling2D())\n",
    "          \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 281s 5ms/step - loss: 0.2451 - acc: 0.9273 - val_loss: 11.2113 - val_acc: 0.0974\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 263s 4ms/step - loss: 0.0837 - acc: 0.9754 - val_loss: 11.8241 - val_acc: 0.1811\n",
      "Epoch 3/12\n",
      "54272/60000 [==========================>...] - ETA: 23s - loss: 0.0568 - acc: 0.9836"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# fit your model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate your model on test data (validation set)\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Use another dataset\n",
    "\n",
    "- Now, you will use a malaria dataset released by Dr. Stefan Jaeger https://ceb.nlm.nih.gov/repositories/malaria-datasets/\n",
    "- The dataset contains a total of 27,558 cell images with equal instances of parasitized and uninfected cells\n",
    "- We have provided this dataset as compact 64x64x3 h5 compressed images and a short script is written below to help you getting started\n",
    "- Details of your task are explained below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# these are small helps to get you started, please change according to your given task\n",
    "# training set positive samples\n",
    "train_dataset_pos = h5py.File('datasets/malaria/data_train_affected.h5', \"r\")\n",
    "train_pos_data=[]\n",
    "train_neg_data=[]\n",
    "# total is 27,558/2 (13778)\n",
    "for i in range (1,20):\n",
    "    train_pos_data.append(train_dataset_pos['X'+str(i)])\n",
    "\n",
    "# training set negative samples\n",
    "train_dataset_neg = h5py.File('datasets/malaria/data_train_unaffected.h5', \"r\")\n",
    "for i in range (1,20):\n",
    "    train_neg_data.append(train_dataset_neg['X'+str(i)])\n",
    "\n",
    "print(train_neg_data[0].shape)\n",
    "print(train_pos_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split your training data into train-validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for pos-neg samples\n",
    "y_train = np.hstack([1]*len(train_pos_data)+[0]*len(train_neg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([train_pos_data, train_neg_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "n_channels=3\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "- Spend sometime here and plan your data: e.g., split data into traing (80%), validation (19%) and test samples (1%)\n",
    "- Train your data using convolution neural network (feel free to use any number of layers) => observe implications of different architectures that you use\n",
    "- Run your model and display your training and validation loss and accuracy\n",
    "- Check your model in tensorboard\n",
    "- Save checkpoint only for best loss\n",
    "- Test using your separated test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alitorch",
   "language": "python",
   "name": "alitorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
